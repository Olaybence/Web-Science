{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "funky-frank",
   "metadata": {},
   "source": [
    "In this notebook, we will dive a little into unsupervised sentiment analysis using the SentiWordNet lexicon. We will use `nltk`, a very well known linrary for NLP.\n",
    "\n",
    "You will need the following libraries installed: `nltk`, `numpy`, and `dataclasses` (this one you can avoid by changing the code a bit). I ran this on Python 3.6 but any Python 3 should work. These are the versions on my computer: \n",
    "\n",
    "```\n",
    "In [65]: numpy.__version__\n",
    "Out[65]: '1.18.4'\n",
    "\n",
    "In [66]: nltk.__version__\n",
    "Out[66]: '3.5'\n",
    "```\n",
    "\n",
    "First, some necessary imports and downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "super-chuck",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     /home/sagnik/nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/sagnik/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('sentiwordnet')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import sentiwordnet as swn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "accepting-performance",
   "metadata": {},
   "source": [
    "If you remember from the slides, SentiWordNet is a big dictionary (map) where each [synset](https://www.geeksforgeeks.org/nlp-synsets-for-a-word-in-wordnet/) is indexed by a key (Part of speech tag, Word). It gives you the positive score, negative score and neutral scores for that key (along with the synset). \n",
    "\n",
    "What is a part of speech tagging? The process of classifying words into their parts of speech and labeling them accordingly.\n",
    "\n",
    "| sentence                                                 | why    | not    | tell | someone | ?           |\n",
    "|----------------------------------------------------------|--------|--------|------|---------|-------------|\n",
    "| part of speech                                           | adverb | adverb | verb | noun    | punctuation |\n",
    "| [part of speech tag](http://www.nltk.org/book/ch05.html) | WRB    | RB     | VB   | NN      | .           |\n",
    "\n",
    "Any part of speech tagger will use a particular `tagset`: or a set of part of speech tags. NLTK uses a tagset from [UPenn](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html), more commonly known as PennTreeBank. \n",
    "\n",
    "How to get sentiment from SentiWordNet?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "acoustic-disability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SentiSynset('happy.a.01'), SentiSynset('felicitous.s.02'), SentiSynset('glad.s.02'), SentiSynset('happy.s.04')]\n",
      "------------------------------\n",
      "word: happy, positive score: 0.875\n",
      "word: happy, negative score: 0.0\n",
      "word: happy, neutral score: 0.125\n",
      "------------------------------\n",
      "------------------------------\n",
      "word: unhappy, positive score: 0.0\n",
      "word: unhappy, negative score: 0.75\n",
      "word: unhappy, neutral score: 0.25\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "positive_word = \"happy\"\n",
    "negative_word = \"unhappy\"\n",
    "pos_tag = \"a\"\n",
    "print(list(swn.senti_synsets(positive_word, pos_tag)))\n",
    "for word in [positive_word, negative_word]:\n",
    "    print(\"-\"*30)\n",
    "    print(f\"word: {word}, positive score: {list(swn.senti_synsets(word, pos_tag))[0].pos_score()}\")\n",
    "    print(f\"word: {word}, negative score: {list(swn.senti_synsets(word, pos_tag))[0].neg_score()}\")\n",
    "    print(f\"word: {word}, neutral score: {list(swn.senti_synsets(word, pos_tag))[0].obj_score()}\")\n",
    "    print(\"-\"*30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-companion",
   "metadata": {},
   "source": [
    "You might have noticed that we use a PoS tag of `a` and not `ADJ`. This is because SentiWordNet uses a different tagset for part of speech tags: `a: all adjectives, r: all adverbs, v: all verbs, n: all nouns`. This requires us to define this function later:\n",
    "\n",
    "```\n",
    "def penn_pos_tag_to_word_net(pos_tag_penn: str) -> Union[str, None]:\n",
    "    word_net_tag = {'NN':wn.NOUN, 'JJ':wn.ADJ,\n",
    "                  'VB':wn.VERB, 'RB':wn.ADV}\n",
    "    return word_net_tag.get(pos_tag_penn[:2])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-playlist",
   "metadata": {},
   "source": [
    "So we know how to get positive, negative, and neutral sentiment score for a word from SentiWordNet. How do we use that to classify a sentence? Let's define some interfaces first.\n",
    "\n",
    "We will assume the use of SentiWordNet, so some parts of the code are the same for any class, i.e, tokenization, pos tagging, conversion of pos tags to SentiWordNet pos tags and scores for each sentiment. The change is in _how_ we use these scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "hidden-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing_extensions import Literal\n",
    "from nltk.tokenize import word_tokenize as tokenize\n",
    "from nltk.tag import pos_tag\n",
    "import numpy as np\n",
    "from nltk.corpus import wordnet as wn\n",
    "from typing import List, Tuple, Union\n",
    "from dataclasses import dataclass\n",
    "\n",
    "class Sentiment(Enum):\n",
    "    POSITIVE = 1\n",
    "    NEGATIVE = 2\n",
    "    NEUTRAL = 3\n",
    "\n",
    "@dataclass\n",
    "class TokenSentiment:\n",
    "    token: str\n",
    "    pos_tag: str \n",
    "    positive: str\n",
    "    negative: str \n",
    "    neutral: str\n",
    "\n",
    "def penn_pos_tag_to_word_net(pos_tag_penn: str) -> Union[str, None]:\n",
    "    word_net_tag = {'NN':wn.NOUN, 'JJ':wn.ADJ,\n",
    "                  'VB':wn.VERB, 'RB':wn.ADV}\n",
    "    return word_net_tag.get(pos_tag_penn[:2])\n",
    "\n",
    "\n",
    "def get_token_sentiment(token: str, pos: str) -> TokenSentiment:\n",
    "    try:\n",
    "        synset_0 = list(swn.senti_synsets(token, pos))[0]\n",
    "        return TokenSentiment(token=token, pos_tag=pos, positive=synset_0.pos_score(), negative=synset_0.neg_score(), \n",
    "                          neutral=synset_0.obj_score())\n",
    "    except IndexError:\n",
    "        return TokenSentiment(token=token, pos_tag=pos, positive=0, negative=0,  neutral=1.) \n",
    "\n",
    "class SentenceSentiment:\n",
    "    def __init__(self, sentence: str):\n",
    "        self.sentence = sentence\n",
    "        self.pos_tokens = [(token, penn_pos_tag_to_word_net(pos_tag)) for token, pos_tag in pos_tag(tokenize(sentence))]\n",
    "        self.token_sentiments = [get_token_sentiment(token, pos) for token, pos in self.pos_tokens if pos is not None]     \n",
    "    \n",
    "    def run(self, **kwargs) -> Literal[Sentiment.POSITIVE, Sentiment.NEGATIVE, Sentiment.NEUTRAL]:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "reasonable-chicken",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TokenSentiment(token='movie', pos_tag='n', positive=0.0, negative=0.0, neutral=1.0),\n",
       " TokenSentiment(token='is', pos_tag='v', positive=0.25, negative=0.125, neutral=0.625),\n",
       " TokenSentiment(token='awesome', pos_tag='a', positive=0.875, negative=0.125, neutral=0.0)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = SentenceSentiment(\"this movie is awesome!\")\n",
    "sentence.token_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "vietnamese-athletics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TokenSentiment(token='movie', pos_tag='n', positive=0.0, negative=0.0, neutral=1.0),\n",
       " TokenSentiment(token='is', pos_tag='v', positive=0.25, negative=0.125, neutral=0.625),\n",
       " TokenSentiment(token='horrible', pos_tag='a', positive=0.0, negative=0.625, neutral=0.375)]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = SentenceSentiment(\"this movie is horrible!\")\n",
    "sentence.token_sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-sailing",
   "metadata": {},
   "source": [
    "Now we will implement the `run` method in a subclass to get the sentiment of a sentence. A simple way to do this would be provide an aggregation of the sentiment scores of the tokens. The aggregation method can be average or max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "vocational-possible",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SentenceSentimentAggregation(SentenceSentiment):\n",
    "    def __init__(self, sentence: str):\n",
    "        super().__init__(sentence)\n",
    "    \n",
    "    def run(self, **kwargs):\n",
    "        aggregation_fn = kwargs['aggregation_fn']\n",
    "        score_dict = {\n",
    "            Sentiment.POSITIVE: aggregation_fn([x.positive for x in self.token_sentiments]),\n",
    "            Sentiment.NEGATIVE: aggregation_fn([x.negative for x in self.token_sentiments]),\n",
    "            Sentiment.NEUTRAL: aggregation_fn([x.neutral for x in self.token_sentiments]),\n",
    "        }\n",
    "        score_vals = score_dict.items()\n",
    "        return sorted(score_vals, key=lambda x:x[1], reverse=True)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "adjustable-nightlife",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sentiment.NEUTRAL: 3>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = SentenceSentimentAggregation(\"this movie is awesome!\")\n",
    "sentence.run(aggregation_fn=np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "disabled-dating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sentiment.NEUTRAL: 3>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = SentenceSentimentAggregation(\"awesome!\")\n",
    "sentence.run(aggregation_fn=np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "renewable-cowboy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sentiment.POSITIVE: 1>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = SentenceSentimentAggregation(\"truly awesome!\")\n",
    "sentence.run(aggregation_fn=np.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-diagnosis",
   "metadata": {},
   "source": [
    "You should try this out with some other examples. In another method, you can take the number of positive vs number of negative words to determine the polarity of the sentence. This is left for exercise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
