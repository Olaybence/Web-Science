{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de",
   "display_name": "Python 3.8.5 64-bit (conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "##########\n",
    "## SST2 ##\n",
    "##########\n",
    "\n",
    "class SentAnalyzer():\n",
    "    def __init__(self, sourcePath):\n",
    "        self.data = pd.read_csv(sourcePath)\n",
    "        self.indexes = self.data['index']\n",
    "        self.labels = self.data['label']\n",
    "        self.texts = self.data['text']\n",
    "        self.textsL1 = self.data.loc[self.data['label'] == 1][\"text\"]\n",
    "        self.textsL0 = self.data.loc[self.data['label'] == 0][\"text\"]\n",
    "    \n",
    "    def checkBalance(self):\n",
    "        len1 = len(self.textsL1)\n",
    "        len0 = len(self.textsL0)\n",
    "        print('Label 1:',len1)\n",
    "        print('Label 0:',len0)\n",
    "        if len1 > len0:\n",
    "            print('Their ratio:',round(abs(len1/len0),2))\n",
    "        else:\n",
    "            print('Their ratio:',round(abs(len0/len1),2))\n",
    "\n",
    "    def nGrams(self, data, minN,maxN,n):\n",
    "        for i in range(minN,maxN):\n",
    "            cv = CountVectorizer(ngram_range = (i,i))\n",
    "            word_count_vector = cv.fit_transform(data)\n",
    "            # print(word_count_vector)\n",
    "            \n",
    "            # Fit the model into the data\n",
    "            tfidf_transformer = TfidfTransformer(smooth_idf=True,use_idf=True) \n",
    "            tfidf_transformer.fit(word_count_vector)\n",
    "            \n",
    "            df_idf = pd.DataFrame(tfidf_transformer.idf_, index = cv.get_feature_names(),columns = [\"tfidf\"])\n",
    "            \n",
    "            # sort ascending \n",
    "            print(df_idf.sort_values(by = ['tfidf'])[:n])\n",
    "    \n",
    "    def lengthCorrelation(self):\n",
    "        lengths = [(lambda x: len(x[1]))(x) for x in self.texts.items()]\n",
    "        lenLab = pd.DataFrame( list(zip(lengths, self.labels)), columns = [\"length\",\"labels\"])\n",
    "        print(lenLab.corr())\n",
    "\n",
    "    def textTfidfValues(self,data):\n",
    "        # this steps generates word counts for the words in your docs \n",
    "        cv = CountVectorizer()\n",
    "        word_count_vector = cv.fit_transform(data)\n",
    "\n",
    "        # print(word_count_vector)\n",
    "        \n",
    "        tfidf_transformer = TfidfTransformer(smooth_idf = True, use_idf = True)\n",
    "        tfidf_transformer.fit(word_count_vector)\n",
    "        \n",
    "        self.tfidf = pd.DataFrame(tfidf_transformer.idf_, index = cv.get_feature_names(), columns = [\"tfidf\"])\n",
    "        \n",
    "        # sort ascending \n",
    "        # print(self.tfidf_transformer.idf_)\n",
    "        return self.tfidf.sort_values(by = [\"tfidf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SST data\n",
    "train = SentAnalyzer(\"stsa.binary.phrases.train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The 5 most common word overall and within the two label.\n",
      "Overall:\n",
      "        tfidf\n",
      "the  2.210299\n",
      "and  2.367068\n",
      "of   2.490469\n",
      "to   2.807791\n",
      "is   3.125087\n",
      "Label 0:\n",
      "        tfidf\n",
      "the  2.188806\n",
      "and  2.463642\n",
      "of   2.493857\n",
      "to   2.670419\n",
      "is   3.045642\n",
      "Label 1:\n",
      "        tfidf\n",
      "the  2.228244\n",
      "and  2.294130\n",
      "of   2.487614\n",
      "to   2.936536\n",
      "is   3.195215\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "print(\"The\", n ,\"most common word overall and within the two label.\")\n",
    "print(\"Overall:\")\n",
    "print(train.textTfidfValues(train.texts)[:n])\n",
    "print(\"Label 0:\")\n",
    "print(train.textTfidfValues(train.textsL0).iloc[:n])\n",
    "print(\"Label 1:\")\n",
    "print(train.textTfidfValues(train.textsL1).iloc[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Whole database\n",
      "        tfidf\n",
      "the  2.210299\n",
      "and  2.367068\n",
      "of   2.490469\n",
      "to   2.807791\n",
      "is   3.125087\n",
      "             tfidf\n",
      "of the    4.053253\n",
      "in the    4.658701\n",
      "the film  4.880207\n",
      "to the    5.155174\n",
      "to be     5.196617\n",
      "                 tfidf\n",
      "one of the    6.096209\n",
      "the film is   6.918348\n",
      "the kind of   7.009320\n",
      "the movie is  7.086281\n",
      "of the year   7.103573\n"
     ]
    }
   ],
   "source": [
    "# Get the n-grams\n",
    "print(\"Whole database\")\n",
    "train.nGrams(train.texts, 1, 4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Label 1 sentences\n",
      "        tfidf\n",
      "the  2.228244\n",
      "and  2.294130\n",
      "of   2.487614\n",
      "to   2.936536\n",
      "is   3.195215\n",
      "             tfidf\n",
      "of the    3.997627\n",
      "in the    4.694099\n",
      "the film  4.920578\n",
      "to the    5.166961\n",
      "and the   5.273170\n",
      "                tfidf\n",
      "one of the   5.771063\n",
      "the film is  6.724343\n",
      "of the year  6.807409\n",
      "of the most  6.906664\n",
      "of the best  6.933097\n"
     ]
    }
   ],
   "source": [
    "# Get the n-grams of Label 1\n",
    "print(\"Label 1 sentences\")\n",
    "train.nGrams(train.textsL1, 1, 4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Label 0 sentences\n",
      "        tfidf\n",
      "the  2.188806\n",
      "and  2.463642\n",
      "of   2.493857\n",
      "to   2.670419\n",
      "is   3.045642\n",
      "              tfidf\n",
      "of the     4.124832\n",
      "in the     4.616176\n",
      "the film   4.831845\n",
      "to be      5.060991\n",
      "the movie  5.115987\n",
      "                 tfidf\n",
      "the movie is  6.610394\n",
      "one of the    6.718383\n",
      "of the film   6.900705\n",
      "the kind of   7.097873\n",
      "of its own    7.137093\n"
     ]
    }
   ],
   "source": [
    "# Get the n-grams of Label 0\n",
    "print(\"Label 0 sentences\")\n",
    "train.nGrams(train.textsL0, 1, 4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "          length    labels\nlength  1.000000 -0.037769\nlabels -0.037769  1.000000\n"
     ]
    }
   ],
   "source": [
    "train.lengthCorrelation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "shape (12805, 12)\nColunm Name :  overall\nColumn Contents :  [4. 4. 5. 5. 5.]\nColunm Name :  verified\nColumn Contents :  [False False False False False]\nColunm Name :  reviewTime\nColumn Contents :  ['10 20, 2010' '10 18, 2010' '10 16, 2010' '10 12, 2010' '10 7, 2010']\nColunm Name :  reviewerID\nColumn Contents :  ['A38NELQT98S4H8' 'A3QJU4FEN8PQSZ' 'ACJT8MUC0LRF0' 'AYUF7YETYOLNX'\n 'A31ICLWQ9CSHRS']\nColunm Name :  asin\nColumn Contents :  ['0321719816' '0321719816' '0321719816' '0321719816' '0321719816']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import gzip\n",
    "from urllib.request import urlopen\n",
    "\n",
    "###################\n",
    "## Amazon Review ##\n",
    "###################\n",
    "\n",
    "# Load in the Amazon Review Data with 5-core\n",
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield json.loads(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df = getDF('Software_5.json.gz')\n",
    "df = df.fillna('')\n",
    "print('shape', df.shape)\n",
    "i = 0\n",
    "for (columnName, columnData) in df.iteritems():\n",
    "    i+=1\n",
    "    if i > 5:\n",
    "        break\n",
    "    print('Colunm Name : ', columnName)\n",
    "    print('Column Contents : ', columnData.values[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install krippendorff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crowdsourcing Exercise\n",
    "import krippendorff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# importing libraries\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CrowdSourcer():\n",
    "    \n",
    "    def __init__(self, sourcePath):\n",
    "        # Get data\n",
    "        self.data = pd.read_csv(sourcePath)\n",
    "\n",
    "        # The feature phrases removed (To separate rating)\n",
    "        cols = []\n",
    "        for i in range(29):\n",
    "            cols.append(\"feature\"+str(i+1))\n",
    "\n",
    "        \n",
    "        self.ratings = self.data.drop([\"Sentence Index\",\"Ground Truth Labels\"] + cols,axis=1)\n",
    "        self.groundTruth = self.data[\"Ground Truth Labels\"]\n",
    "        self.workers = self.ratings.columns\n",
    "        # features = data.drop([\"Sentence Index\",\"Ground Truth Labels\"] + workers.values[:], axis = 1)\n",
    "        # print(self.ratings)\n",
    "\n",
    "    def calcKrippendorff(self):\n",
    "        missing = \"\"        \n",
    "        kripCoef = krippendorff.alpha(reliability_data = self.ratings)\n",
    "        print(\"Krippendorff coeficient: %.3f\" % kripCoef)\n",
    "\n",
    "    # Generate the prediction matrix out of the global sheet data.\n",
    "    def trainByCS(self, X_train, y_train,voteType = \"hard\", solver = \"lbfgs\"):\n",
    "        # group / ensemble of models\n",
    "        self.estimator = []\n",
    "        self.estimator.append((\"LR\", \n",
    "                        LogisticRegression(solver = solver, \n",
    "                                            multi_class =\"multinomial\", \n",
    "                                            max_iter = 200)))\n",
    "        self.estimator.append((\"SVC\", SVC(gamma = \"auto\", probability = True)))\n",
    "        self.estimator.append((\"DTC\", DecisionTreeClassifier()))\n",
    "\n",
    "        # Voting Classifier with hard voting\n",
    "        self.voters = VotingClassifier(estimators = self.estimator, voting = voteType)\n",
    "        self.voters.fit(X_train, y_train)\n",
    "        \n",
    "\n",
    "    def checkPrediction(self,ratings,truths):\n",
    "        y_pred = self.voters.predict(ratings)\n",
    "        # print(whole)\n",
    "        misses = 0\n",
    "        for guess,truth in zip(y_pred, truths):\n",
    "            # print(guess,truth)\n",
    "            if guess != truth:\n",
    "                misses += 1\n",
    "        print(misses, \"miss(es) out of\",len(truths), \" accurary:\", str(100*round( 1-(misses/len(truths)) , 2)) + \"%\" )\n",
    "        return str(100*round( 1-(misses/len(truths)) , 2))\n",
    "        \n",
    "\n",
    "collabData = CrowdSourcer(\"GlobalSheet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Krippendorff coeficient: 0.005\n"
     ]
    }
   ],
   "source": [
    "collabData.calcKrippendorff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "size of train data: 9\n",
      "size of test data: 92.0\n",
      "4 miss(es) out of 92  accurary: 96.0%\n",
      "3 miss(es) out of 92  accurary: 97.0%\n",
      "4 miss(es) out of 92  accurary: 96.0%\n",
      "4 miss(es) out of 92  accurary: 96.0%\n",
      "4 miss(es) out of 92  accurary: 96.0%\n"
     ]
    }
   ],
   "source": [
    "# Training and testing the crowdsourcing\n",
    "testSize = 0.91\n",
    "\n",
    "print(\"size of train data:\", round( len(collabData.groundTruth)*(1-testSize)) )\n",
    "print(\"size of test data:\",  round( len(collabData.groundTruth)*testSize,0) )\n",
    "\n",
    "#### TESTING PARAMETERS ####\n",
    "# solvers = [\"newton-cg\",\"lbfgs\"]\n",
    "# for s in solvers:\n",
    "#     print(s)\n",
    "#     for j in range(2):\n",
    "#         vote = \"hard\"\n",
    "#         if j == 1:\n",
    "#             vote = \"soft\"\n",
    "#         print(\"with\", vote,\"vote\")\n",
    "#         for i in range(20):\n",
    "#             X_train, X_test, y_train, y_test = train_test_split(collabData.ratings,\n",
    "#                                                                 collabData.groundTruth,\n",
    "#                                                                 test_size = testSize,\n",
    "#                                                                 random_state = 42)\n",
    "\n",
    "#             # collabData.trainByCS(X_train,y_train,\"soft\")\n",
    "#             collabData.trainByCS(X_train,y_train,vote,s)\n",
    "#             collabData.checkPrediction(X_test,y_test)\n",
    "#############################\n",
    "\n",
    "for i in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(collabData.ratings,\n",
    "                                                        collabData.groundTruth,\n",
    "                                                        test_size = testSize,\n",
    "                                                        random_state = 42)\n",
    "\n",
    "    collabData.trainByCS(X_train,y_train,\"hard\")\n",
    "    collabData.checkPrediction(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "start\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# SKLearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "class Recommender(SentAnalyzer):\n",
    "    def __init__(self, sourcePath):\n",
    "        SentAnalyzer.__init__(self, sourcePath)\n",
    "        self.testSize = 0.5\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.texts,\n",
    "                                                                                self.labels,\n",
    "                                                                                test_size = testSize,\n",
    "                                                                                random_state = 42)\n",
    "\n",
    "    def getDocTermMtx(self):\n",
    "        self.cv = CountVectorizer(ngram_range=(1, 3), lowercase = True)\n",
    "        self.cv.fit(self.texts.values)\n",
    "        self.wcVector = self.cv.transform(self.texts.values)\n",
    "\n",
    "        self.vocab = list(self.cv.vocabulary_.items())\n",
    "        print('Vocabulary len:',len(self.vocab))\n",
    "        print(\"Word Vector matrix:\",self.wcVector.shape)\n",
    "\n",
    "        # Unigram Tf-Idf\n",
    "        \n",
    "        self.tfidf = TfidfTransformer()\n",
    "        self.tfidf.fit(self.wcVector)\n",
    "\n",
    "        # Numericalize the train dataset\n",
    "        self.docTermMtx = self.tfidf.transform(self.wcVector)\n",
    "        print('Document-term matrix',self.docTermMtx.shape)\n",
    "        \n",
    "    def dimensionReduce(self):\n",
    "        svd = TruncatedSVD(n_components = 100, n_iter=7, random_state=42)\n",
    "        svd.fit(self.docTermMtx)\n",
    "\n",
    "        print(svd.explained_variance_ratio_)\n",
    "        print()\n",
    "        print(svd.explained_variance_ratio_.sum())\n",
    "        print()\n",
    "        print('Eigen values',svd.singular_values_)\n",
    "\n",
    "    def predictWithModels(self):\n",
    "        self.model = Word2Vec.load(\"word2vec.model\")\n",
    "        self.model.train(self.X_train, total_examples=1, epochs=1)\n",
    "        # print(\"train score:\", model.score(self.X_train, self.y_train))\n",
    "        # print(\"test score:\", model.score(self.X_test, self.y_test))\n",
    "\n",
    "print(\"start\")\n",
    "sstRec = Recommender(\"stsa.binary.phrases.train\")\n",
    "# sstRec.predictWithModels()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Vocabulary len: 199518\nWord Vector matrix: (76961, 199518)\nDocument-term matrix (76961, 199518)\n"
     ]
    }
   ],
   "source": [
    "sstRec.getDocTermMtx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.00121149 0.00128441 0.00117962 0.00099757 0.00091534 0.00089047\n 0.00086159 0.00084731 0.00080133 0.00077393 0.00076205 0.00075188\n 0.00071879 0.00068555 0.00066685 0.00064739 0.00064214 0.0006407\n 0.00059597 0.00059384 0.00059141 0.0005794  0.00057164 0.00056456\n 0.00055109 0.00054799 0.00054204 0.00052532 0.00052025 0.00051376\n 0.0005109  0.00050428 0.00050088 0.00048616 0.00047748 0.00046825\n 0.00046533 0.0004636  0.00045509 0.0004464  0.00043525 0.0004327\n 0.00042803 0.00041918 0.00041732 0.00041331 0.00040727 0.00040469\n 0.00040002 0.00039647 0.00039161 0.00038776 0.00038475 0.00037984\n 0.00037849 0.00037695 0.00037333 0.00036999 0.00036589 0.00036348\n 0.0003602  0.00035359 0.00035304 0.00035192 0.00034937 0.00034482\n 0.00034234 0.00033849 0.00033823 0.00033695 0.00033581 0.0003336\n 0.00033319 0.00033089 0.00032919 0.00032556 0.00032508 0.00032314\n 0.00031941 0.00031857 0.00031762 0.00031692 0.0003126  0.00031172\n 0.00030996 0.00030882 0.00030611 0.00030461 0.00030224 0.00029964\n 0.00029885 0.00029605 0.00029378 0.00029267 0.00029151 0.00029001\n 0.00028876 0.00028735 0.00028353 0.00028281]\n\n0.04741929969288505\n\nEigen values [15.76324619 10.15302262  9.5266174   8.7586527   8.38407664  8.28329997\n  8.14538265  8.0662531   7.8640452   7.71505932  7.65241526  7.6007958\n  7.43457131  7.25709615  7.16536849  7.06264316  7.02210445  7.01434227\n  6.76962651  6.75860548  6.73949633  6.67183972  6.63268617  6.59197855\n  6.50732667  6.48707436  6.451597    6.35203422  6.32097927  6.28100923\n  6.26976226  6.22487458  6.20274605  6.11389828  6.05622682  6.00233988\n  5.98137985  5.96654186  5.91343898  5.85937747  5.78336876  5.76988355\n  5.73343857  5.67436095  5.66231004  5.6336837   5.5931551   5.57738309\n  5.54625773  5.51800558  5.48518483  5.45672358  5.437092    5.40126019\n  5.39116824  5.38118968  5.35775418  5.33131999  5.300594    5.28321615\n  5.26071313  5.21092206  5.20918639  5.20076204  5.18014972  5.14574079\n  5.12844488  5.09964761  5.0971489   5.08823816  5.07928166  5.06128528\n  5.06093658  5.04236299  5.02837013  4.99995712  4.99633044  4.9822975\n  4.95398194  4.94617041  4.93947414  4.93320896  4.8995836   4.89309492\n  4.87917329  4.8701978   4.84975092  4.83675176  4.8175794   4.79677689\n  4.79066024  4.76794503  4.75030128  4.74089501  4.73146077  4.71915834\n  4.70947758  4.69740795  4.66606522  4.66021088]\n"
     ]
    }
   ],
   "source": [
    "sstRec.dimensionReduce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I tried the differences between \n",
    "# the CountVectorizer with different parameters\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "# Unigram Counts\n",
    "\n",
    "unigram_vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
    "unigram_vectorizer.fit(sstRec.texts.values)\n",
    "\n",
    "X_train_unigram = unigram_vectorizer.transform(sstRec.texts.values)\n",
    "\n",
    "# Unigram Tf-Idf\n",
    "unigram_tf_idf = TfidfTransformer()\n",
    "unigram_tf_idf.fit(X_train_unigram)\n",
    "\n",
    "X_train_unigram_tf_idf = unigram_tf_idf.transform(X_train_unigram)\n",
    "\n",
    "# trigram Counts\n",
    "trigram_vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "trigram_vectorizer.fit(sstRec.texts.values)\n",
    "\n",
    "X_train_trigram = trigram_vectorizer.transform(sstRec.texts.values)\n",
    "\n",
    "\n",
    "# trigram Tf-Idf\n",
    "trigram_tf_idf = TfidfTransformer()\n",
    "trigram_tf_idf.fit(X_train_trigram)\n",
    "\n",
    "X_train_trigram_tf_idf = trigram_tf_idf.transform(X_train_trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unigram Counts\n",
      "Train score: 0.92 ; Validation score: 0.88\n",
      "\n",
      "Unigram Tf-Idf\n",
      "Train score: 0.9 ; Validation score: 0.87\n",
      "\n",
      "Trigram Counts\n",
      "Train score: 0.97 ; Validation score: 0.91\n",
      "\n",
      "Trigram Tf-Idf\n",
      "Train score: 0.93 ; Validation score: 0.88\n",
      "\n",
      "Unigram Counts\n",
      "Train score: 0.92 ; Validation score: 0.88\n",
      "\n",
      "Unigram Tf-Idf\n",
      "Train score: 0.9 ; Validation score: 0.87\n",
      "\n",
      "Trigram Counts\n",
      "Train score: 0.97 ; Validation score: 0.91\n",
      "\n",
      "Trigram Tf-Idf\n",
      "Train score: 0.93 ; Validation score: 0.88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "\n",
    "def train_and_show_scores(X, y, title) -> None:\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X, y, train_size = 0.75, stratify = y\n",
    "    )\n",
    "\n",
    "    clf = SGDClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_score = clf.score(X_train, y_train)\n",
    "    valid_score = clf.score(X_valid, y_valid)\n",
    "    print(f'{title}\\nTrain score: {round(train_score, 2)} ; Validation score: {round(valid_score, 2)}\\n')\n",
    "\n",
    "y_train = sstRec.labels.values\n",
    "\n",
    "train_and_show_scores(X_train_unigram, y_train, 'Unigram Counts')\n",
    "train_and_show_scores(X_train_unigram_tf_idf, y_train, 'Unigram Tf-Idf')\n",
    "train_and_show_scores(X_train_trigram, y_train, 'Trigram Counts')\n",
    "train_and_show_scores(X_train_trigram_tf_idf, y_train, 'Trigram Tf-Idf')\n",
    "\n",
    "train_and_show_scores(X_train_unigram, y_train, 'Unigram Counts')\n",
    "train_and_show_scores(X_train_unigram_tf_idf, y_train, 'Unigram Tf-Idf')\n",
    "train_and_show_scores(X_train_trigram, y_train, 'Trigram Counts')\n",
    "train_and_show_scores(X_train_trigram_tf_idf, y_train, 'Trigram Tf-Idf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}